# Game Generation Workflow (Integrated Version)

## Overview

This document defines a practical workflow that integrates technical automation with human-LLM collaboration in tag-based automated game generation.

**Core Principles of Integration:**

- Maximize technical automation (novelty assurance, quality evaluation, balance adjustment)
- Focus human intervention on strategic points (creative judgment, experience evaluation)
- Efficient feedback loops (70% LLM autonomy / 30% human validation)
- Clear completion criteria and gate management at each phase

**Prerequisite Knowledge:**

- This workflow is built upon the technical foundations of `novelty_game_generation.md` (novelty assurance mechanisms) and `game_evaluation_system.md` (quality evaluation system)
- Design philosophy inherits the collaborative approach from `one-button-game-design-guide.md` and `one-button-game-implementation-guide.md`
- Implementation conforms to the API reference in `crisp-game-lib-guide.md`

## Basic Flow Overview

```
Phase 0: Tag Selection and Initial Validation (10 min)
  â†“ âœ… Tag Approval
Phase 1: Problem-Solution Structuring (15 min)
  â†“ âœ… Logic Verification
Phase 2: Creative Synthesis and Novelty Assurance (15 min)
  â†“ âœ… Creativity Confirmation
Phase 3: Implementation and Prototyping (20-30 min)
  â†“ âœ… Basic Functionality Confirmation
Phase 4: Validation and Balance Adjustment (30-45 min)
  â†“ âœ… Balance Approval
Phase 5: Final Validation and Completion Approval (10 min)
  â†“ âœ… Final Approval
Completion & Metrics Recording
```

**Estimated Time:** 100-125 minutes (1.5-2 hours)
**Actual Human Work:** Approximately 30 minutes (feedback and judgment only)

---

## Universal Execution Protocol (Common to All Phases)

All phases follow this protocol:

### Basic Cycle

```markdown
ã€Standard Flow for Each Phaseã€‘

1. ðŸ¤– LLM AUTO-EXECUTE: Execute automated processing â†’ Present results
2. ðŸ¤ HUMAN CHECKPOINT: Provide feedback (using templates)
3. ðŸ¤– LLM AUTO-ADJUST: Execute adjustments (as needed)
4. âœ… COMPLETION CHECK: Verify completion criteria â†’ Next phase or iterate

ã€Iteration Conditionsã€‘

- Repeat Steps 2-4 until completion criteria are met
- Do not proceed until human explicitly says "proceed"
```

### Prohibited and Required Actions

```markdown
ðŸš« FORBIDDEN:

- Presenting multiple options ("Which is better, Option A or B?")
- Implementation with assumptions (leaving ambiguities unresolved)
- Proceeding without feedback (skipping validation)
- Moving to next phase before meeting completion criteria

âœ… REQUIRED:

- Ask one clear question at a time when ambiguity detected
- Single implementation â†’ Test â†’ Feedback â†’ Adjustment cycle
- Do not proceed until completion criteria are met
- Obtain human approval at all Checkpoints
```

---

## Question Management System (Applied to All Phases)

Defines how to respond when ambiguity is detected.

### Level 1: Blocker Question (Critical unknown that stops implementation)

```markdown
ã€Response Procedureã€‘

1. ðŸ¤– Immediately halt implementation
2. ðŸ¤– Present one clear question
   - Yes/No format or specific options
   - Attach brief background information
3. ðŸ¤ Wait for human response
4. ðŸ¤– Continue implementation after receiving answer

ã€Good Exampleã€‘
"Confirmation: When colliding with enemies, does the game immediately end?
Or does health decrease?
(This decision affects the game loop design)"

ã€Bad Exampleã€‘
"Please tell me details about enemy behavior" (scope too broad)
```

### Level 2: Assumption Clarification (When assumption is needed)

```markdown
ã€Response Procedureã€‘

1. ðŸ¤– Explicitly state "Assumption: [specific content]"
2. ðŸ¤– Explain reason for assumption
3. ðŸ¤ Wait for human approval
4. ðŸ¤– After approval, implement and record assumption in code comments

ã€Exampleã€‘
"Assumption: When reaching screen edge, player warps to opposite side

Reason: Tag 'field:wrap' is selected, which is a typical implementation pattern.
May I proceed with implementation based on this assumption?"
```

### Level 3: Parameter Question (Resolvable through feedback)

```markdown
ã€Response Policyã€‘

- Do not ask about parameter values (speed, timing, etc.) before implementing
- Implement with standard values â†’ Present â†’ Collect feedback
- Wait for specific adjustment instructions based on human experience

ã€Good Flowã€‘
ðŸ¤– "Implemented with MOVE_SPEED = 1.0. Please test"
ðŸ¤ "Movement is too slow"
ðŸ¤– "Adjusting MOVE_SPEED to 1.5"

ã€Bad Flowã€‘
ðŸ¤– "Which MOVE_SPEED would be better: 0.5, 1.0, or 1.5?"
```

---

## Phase 0: Tag Selection and Initial Validation

**Purpose:** Auto-select high-novelty tag combinations and obtain human approval
**Estimated Time:** 10 minutes
**Main Processing:** Cross-category constraints, novelty score calculation, initial validity check

### ðŸ¤– LLM AUTO-EXECUTE

```bash
# Automatic selection via cross-category constraints
npm run generate-constraints

# Example output:
# player:multiple + field:roughness + weapon:explosion + rule:physics + obstacle:penalty
# â†’ 5 categories, 40% dominance rate, good complexity balance
```

**Automated Processing Content:**

1. Execute `scripts/generate_cross_category_constraints.js`
2. Validate cross-category constraints:
   - Minimum categories: 3 or more categories
   - Dominance prevention: Single category exceeding 50% prohibited
   - Complexity balance: Mix of minimal/low/medium levels
3. Calculate novelty score for tag combinations (using `knowledge/tag_categories_enhanced.csv`)
4. Format constraint violation check results

**Presentation Format:**

```markdown
ã€Selection Resultsã€‘

- Tags: player:multiple, field:roughness, weapon:explosion, rule:physics, obstacle:penalty
- Categories: 5 (player, field, weapon, rule, obstacle)
- Dominance rate: player 20%, field 20%, weapon 20%, rule 20%, obstacle 20%
- Complexity balance: medium 60%, low 40%
- Novelty score: 0.78 (tag pair novelty rate)

ã€Constraint Checkã€‘
âœ… Minimum categories: 5 >= 3
âœ… Dominance prevention: max 20% <= 50%
âœ… Complexity balance: medium + low mix
```

### ðŸ¤ HUMAN CHECKPOINT

**Feedback Collection Questions:**

```markdown
Please verify the validity of the selected tag combination:

1. Is this tag combination attractive?

   - Are there interesting interactions you can imagine?
   - Are there any awkward combinations?

2. Is the category balance appropriate?

   - Do you feel any categories are insufficient/excessive?

3. What problem category is anticipated from these tags?
   - Movement/Navigation
   - Resource/Collection
   - Timing/Coordination
   - Information/Visibility
   - State/Balance
   - Physics/Forces
   - Pattern/Signal

ã€Response Optionsã€‘
âœ… "Approved, proceed" + indicate anticipated problem category
ðŸ”„ "Change tag X to tag Y" â†’ Re-select
âŒ "Overall lacking appeal" â†’ Complete re-selection
```

**Expected Human Response:**

- If approved: "Approved. Physics/Forces problem anticipated"
- If change: "Change weapon:explosion to weapon:beam"
- If rejected: "Combination is mediocre. Re-select"

### âœ… COMPLETION CRITERIA

```markdown
â–¡ Tag selection script execution completed
â–¡ No constraint violations (category count, dominance rate, complexity balance)
â–¡ Human approval obtained
â–¡ Anticipated problem category identified (human indicated or LLM proposed)

â†’ If all met, proceed to Phase 1
```

---

## Phase 1: Problem-Solution Structuring

**Purpose:** Design clear problem-solution pair from tag characteristics and verify logic
**Estimated Time:** 15 minutes
**Main Processing:** Problem category selection, template completion, simple verb design, logic verification

### ðŸ¤– LLM AUTO-EXECUTE

**Step 1: Tag Characteristics Analysis and Problem Category Selection**

```markdown
ã€Tag Mechanics Analysisã€‘
Extract core behavior patterns from tags selected in Phase 0:

Example: player:multiple, field:gravity, weapon:explosion

- player:multiple â†’ Simultaneous control of multiple objects, individual state management
- field:gravity â†’ Gravitational pull toward center, force changes with distance
- weapon:explosion â†’ Area effect, timing element

ã€Problem Category Selectionã€‘
Select one optimal category based on category anticipated by human in Phase 0, or from tag characteristics:

Selection: Physics/Forces
Reason: Dealing with physical force of gravity from field:gravity is the central challenge
```

**Step 2: Problem Template Completion**

```markdown
SELECTED TAGS: player:multiple, field:gravity, weapon:explosion
SELECTED CATEGORY: Physics/Forces

Player wants to: Place multiple objects in safe zones
Current obstacle: Gravity pulls them toward center
Environmental constraint: Cannot control individually (one button only)
```

**Step 3: Baseline Verb Identification + Light Improvement**

```markdown
STAGE 1: BASELINE VERB IDENTIFICATION

- Basic verb candidates: Push, Explode, Repel
- REVERSE CHECK: "Can this verb solve [obstacle] to achieve [goal]?"
  â†’ "Explode" can push back against gravity âœ…

BASELINE VERB: "Tap to explode"

STAGE 2: LIGHT IMPROVEMENT (Maintain 3-second rule)

- Add one simple refinement: Explosion radius changes with charge time
- Improved verb: "Hold to charge explosion radius"

STAGE 3: ONE-BUTTON COMPATIBILITY CHECK
â–¡ Achievable with Press/Hold/Release only? âœ…
â–¡ No hidden position selection or directional input? âœ…
â–¡ Satisfies 3-second rule? âœ…
```

**Step 4: One-Button Control Design**

```markdown
CONTROL DESIGN:

- Press (Tap): Execute small-scale explosion immediately
- Hold (1-3 sec): Explosion radius charges (visual indicator)
- Release (after hold): Execute explosion with charged radius

VALIDATION:
â–¡ Achievable with one button only? âœ…
â–¡ No position selection needed? âœ… (explosion is omnidirectional from center)
â–¡ Player can achieve goal? âœ… (push out with timed explosion)
```

### ðŸ¤ HUMAN CHECKPOINT

**Feedback Collection Questions:**

```markdown
Please verify the validity of the problem-solution logic:

ã€Problem Definitionã€‘

- Player wants to: Place multiple objects in safe zones
- Current obstacle: Gravity pulls them toward center
- Environmental constraint: Cannot control individually (one button only)

Is this problem definition clear and attractive?

ã€Solutionã€‘

- Baseline verb: "Tap to explode"
- Light improvement: "Hold to charge explosion radius"
- Control: Press=small explosion, Hold=charge, Release=large explosion

Is this solution intuitive? Can it be understood within 3 seconds?

ã€Logic Chainã€‘
Problem (pulled by gravity)
â†“
Solution (push back with explosion, adjust timing with charge)
â†“
Goal (place in safe zones)

Is this logical flow natural? Any contradictions?

ã€Response Optionsã€‘
âœ… "Approved, logical and interesting"
ðŸ”„ "Adjust problem definition: [specific suggestion]"
ðŸ”„ "Adjust solution: [specific suggestion]"
âŒ "Fundamental contradiction: [reason]" â†’ Redesign Phase 1
```

**Ambiguity Detection:**

If LLM detects unclear points:

```markdown
ðŸ¤– Question (Level 1 Blocker):
"Confirmation: Are safe zones fixed positions on screen?
Or do they move dynamically?
(This decision affects explosion timing design)"

ðŸ¤ Human Answer:
"Fixed positions"

ðŸ¤– Acknowledgment:
"Understood. Will proceed with design as fixed-position safe zones"
```

### âœ… COMPLETION CRITERIA

```markdown
â–¡ Problem category selection completed
â–¡ Problem template completed (Player wants to / Obstacle / Constraint)
â–¡ Baseline verb + Light improvement design completed
â–¡ One-button compatibility verified (Press/Hold/Release)
â–¡ Human logic confirmation obtained
â–¡ All ambiguities resolved

â†’ If all met, proceed to Phase 2
```

---

## Phase 2: Creative Synthesis and Novelty Assurance

**Purpose:** Clarify differentiation from existing games and verify implementation feasibility
**Estimated Time:** 15 minutes
**Main Processing:** Exclusion filtering, logical walkthrough, warning sign detection, visual communication design

### ðŸ¤– LLM AUTO-EXECUTE

**Step 5: Exclusion Filtering (Clarification of Differentiation Elements)**

```markdown
ã€Analysis of Dominant Patterns in Existing Gamesã€‘
Research existing implementations of corresponding tags from `knowledge/tag_code_map.json` and `knowledge/games/`:

Example: Existing games with "gravity" tag â†’ Use attraction to collect
Example: Existing games with "explosion" tag â†’ Attack means to defeat enemies

ã€Explicit Exclusion Targetsã€‘
â–¡ Victory condition: "Push back with explosions" instead of existing "collect using attraction"
â–¡ Control method: "Charge-based timed explosion" instead of existing "continuous explosions"
â–¡ Visual representation: "Defensive pushing back" instead of existing "attack effects"
â–¡ Game loop: "Placement optimization" instead of existing "enemy elimination"

ã€Code Reuse Constraintsã€‘

- Code reuse rate: 30% or less
- Prohibited to reuse function/variable names
- Prohibited to directly reuse existing victory condition logic
```

**Step 6: Logical Walkthrough (Implementation Feasibility Verification)**

```markdown
WALKTHROUGH SEQUENCE:

Start: Multiple objects being pulled by gravity toward center
â†“
Action 1: Player presses button (Tap)
Result 1: Small explosion executed
Feedback 1: Explosion effect, objects move slightly outward
â†“
Action 2: Player holds button
Result 2: Charge indicator displayed enlarging
Feedback 2: Charge range visually expands, charge sound
â†“
Action 3: Player releases button
Result 3: Explosion executed with charged range
Feedback 3: Large explosion effect, objects pushed out significantly
â†“
Action 4: Player waits
Result 4: Gravity pulls objects toward center again
Feedback 4: Objects move toward center
â†“
Action 5: Player times explosion correctly
Result 5: Objects reach safe zones
Feedback 5: Score added, achievement sound, visual effect
â†“
End: Goal achieved with all objects placed in safe zones

VALIDATION CHECK:
â–¡ Every action uses only press/hold/release? âœ…
â–¡ Goal logically achievable? âœ…
â–¡ No directional input required? âœ…
â–¡ No position selection required? âœ…
â–¡ Problem-solution logic maintained? âœ…
```

**Step 7: Warning Sign Detection (Automatic Defect Check)**

```markdown
ðŸš« RED FLAGS CHECK:

ã€One-Button Constraint Violationsã€‘
â–¡ Description includes "player chooses", "player aims", "player selects"? âŒ
â–¡ Requires position selection beyond press/hold/release timing? âŒ
â–¡ Multiple control schemes or input modes needed? âŒ

ã€Problem Definition Issuesã€‘
â–¡ Abstract expressions ("use," "utilize") cannot be concretized? âŒ
â–¡ Forces/actions needed for goal achievement don't exist in system? âŒ
â–¡ Phenomena violating physics laws occur without basis? âŒ

ã€Gameplay Depth Issuesã€‘
â–¡ Player can clear by ignoring one mechanic entirely? âŒ
â–¡ Game reduces to simple parameter optimization (hold time only)? âŒ
â–¡ Only one strategy exists for success? âŒ

RESULT: âœ… No red flags detected
```

**Step 8: Visual Communication Design**

```markdown
VISUAL COMMUNICATION SPECIFICATION:

ã€Problem Indicationã€‘

- How: Highlight safe zones (green border), display dangerous center area in red
- Example: Red danger zone in screen center, green safe zones on outer perimeter

ã€Solution Availabilityã€‘

- How: Flash button icon when charge available, audio cue at optimal timing
- Example: Button icon at screen bottom, white flash when charge available

ã€Action Feedbackã€‘

- Press: Small explosion effect (particles), short explosion sound
- Hold: Charge circle expands (center to outside), charge sound loop
- Release: Large explosion effect, shockwave circle expands, explosion sound
- Example:
  - Press: play("hit"), particle(center, {count: 10})
  - Hold: Circle expands from radius 10â†’30 over 1 second
  - Release: play("explosion"), particle(center, {count: 30, speed: 5})

ã€Progress Indicatorsã€‘

- How: Display number of objects placed in safe zones / total
- Example: "3/5 SAVED" text at top of screen

ã€Failure Warningã€‘

- How: Objects flash warning color when approaching center, play danger sound
- Example: Objects within center radius 10 flash red + play("hit")
```

### ðŸ¤ HUMAN CHECKPOINT

**Feedback Collection Questions:**

```markdown
Please verify creativity and implementation feasibility:

ã€Concept Evaluationã€‘

- Is this game concept fresh and attractive?
- Is the difference from existing games clear?
- Would you want to play this?

ã€Differentiation Elementsã€‘
Explicitly stated exclusion targets:

- Victory condition: "Push back with explosions" (not existing "collect with attraction")
- Control method: "Charge-based timed explosion" (not existing "continuous explosions")

Do these differentiations feel sufficient?

ã€Implementation Feasibilityã€‘
Please review the logical walkthrough:

1. Objects pulled by gravity
2. Player pushes back with charged explosion
3. Place in safe zones with good timing

Are there any impossibilities or contradictions in this flow?

ã€Visual Communicationã€‘
Are the presented visual feedback specifications appropriate?

- Problem recognition ease
- Immediate action feedback
- Progress clarity

ã€Response Optionsã€‘
âœ… "Approved, implementable and attractive"
ðŸ”„ "Adjust concept: [specific suggestion]"
ðŸ”„ "Add differentiation elements: [specific suggestion]"
ðŸ”„ "Adjust visual feedback: [specific suggestion]"
âŒ "Fundamental problem: [reason]" â†’ Return to Phase 1
```

**Warning Signs Collaborative Check:**

```markdown
ðŸ¤– LLM automatic detection result:
âœ… No red flags detected in automated check

ðŸ¤ HUMAN judgment request:
Please provide human intuitive judgment on the following:

ã€Engagement Depthã€‘

- Does this mechanic seem to generate strategic depth?
- Is there risk of falling into simple repetition?

ã€Innovation Genuinenessã€‘

- Does this "light refinement" (charge-based explosion) contribute to essential fun?
- Is it just a superficial gimmick?

Please point out any issues specifically.
```

### âœ… COMPLETION CRITERIA

```markdown
â–¡ Exclusion filtering completed (differentiation elements clarified)
â–¡ Logical walkthrough verified (implementation feasibility confirmed)
â–¡ Warning sign automatic check passed (0 Red Flags)
â–¡ Visual communication specification completed
â–¡ Human creativity confirmation obtained
â–¡ Human Engagement/Innovation judgment obtained

â†’ If all met, proceed to Phase 3
```

---

## Phase 3: Implementation and Prototyping

**Purpose:** Generate Crisp Game Library compliant code and verify basic functionality
**Estimated Time:** 20-30 minutes
**Main Processing:** Code implementation, similarity check, prototyping, basic functionality verification

### ðŸ¤– LLM AUTO-EXECUTE

**Step 1: Crisp Game Library Compliant Code Generation**

```javascript
// Generate as tmp/games/<slug>.js
// Required:
// - 2-space indent, trailing semicolons
// - Global variables: title, description, options, update()
// - Balance adjustment target parameters in const UPPER_SNAKE_CASE = value; format
// - Reflect visual communication specification (Phase 2 Step 8) in implementation

title = "GRAVITY OUTPOST";

description = `[Hold] Charge explosion
Push objects to safe zone`;

options = {
  viewSize: { x: 100, y: 100 },
  isPlayingBgm: true,
  isReplayEnabled: true,
  seed: 1,
};

// Balance adjustment target parameters (cooperative evolution system compatible)
const GRAVITY_STRENGTH = 0.1;
const SMALL_EXPLOSION_FORCE = 2;
const CHARGE_RATE = 0.5;
const MAX_CHARGE_RADIUS = 30;
const OBJECT_COUNT = 5;
const SAFE_ZONE_RADIUS = 15;

let objects;
let chargeLevel;
let centerPos;

function update() {
  if (!ticks) {
    // Initialization
    centerPos = vec(50, 50);
    objects = [];
    times(OBJECT_COUNT, () => {
      objects.push({
        pos: vec(rnd(30, 70), rnd(30, 70)),
        vel: vec(0, 0),
        safe: false,
      });
    });
    chargeLevel = 0;
  }

  // Draw center area (danger zone)
  color("light_red");
  arc(centerPos, SAFE_ZONE_RADIUS, 3);

  // Draw safe zones (4 locations on perimeter)
  color("light_green");
  const safeZones = [vec(15, 15), vec(85, 15), vec(15, 85), vec(85, 85)];
  safeZones.forEach((zone) => {
    arc(zone, 10, 2);
  });

  // Explosion control
  if (input.isPressed) {
    chargeLevel = min(MAX_CHARGE_RADIUS, chargeLevel + CHARGE_RATE);

    // Display charge indicator
    color("light_cyan");
    arc(centerPos, chargeLevel, 2);
  }

  if (input.isJustReleased && chargeLevel > 0) {
    // Execute explosion
    play("explosion");
    particle(centerPos, { count: 30, speed: chargeLevel * 0.2 });

    // Apply force to objects
    objects.forEach((obj) => {
      const diff = vec(obj.pos).sub(centerPos);
      const dist = diff.length;
      if (dist < chargeLevel) {
        const force = diff.normalize().mul((chargeLevel - dist) * 0.3);
        obj.vel.add(force);
      }
    });

    chargeLevel = 0;
  }

  if (input.isJustPressed) {
    // Small explosion
    play("hit");
    particle(centerPos, { count: 10, speed: 2 });
    objects.forEach((obj) => {
      const diff = vec(obj.pos).sub(centerPos);
      const dist = diff.length;
      if (dist < 15) {
        const force = diff.normalize().mul(SMALL_EXPLOSION_FORCE);
        obj.vel.add(force);
      }
    });
  }

  // Update objects
  let savedCount = 0;
  objects.forEach((obj) => {
    // Gravity (attraction to center)
    const toCenter = vec(centerPos).sub(obj.pos);
    const dist = toCenter.length;
    obj.vel.add(toCenter.normalize().mul(GRAVITY_STRENGTH));

    // Velocity damping
    obj.vel.mul(0.98);

    // Position update
    obj.pos.add(obj.vel);
    obj.pos.clamp(5, 95, 5, 95);

    // Safe zone check
    obj.safe = false;
    safeZones.forEach((zone) => {
      if (obj.pos.distanceTo(zone) < 10) {
        obj.safe = true;
      }
    });

    // Danger warning
    if (dist < SAFE_ZONE_RADIUS) {
      color("red");
      if (ticks % 10 < 5) {
        box(obj.pos, 6);
      }
    } else {
      color(obj.safe ? "green" : "blue");
      box(obj.pos, 6);
    }

    if (obj.safe) savedCount++;
  });

  // Progress display
  color("black");
  text(`${savedCount}/${OBJECT_COUNT} SAVED`, 3, 10);

  // Goal check
  if (savedCount === OBJECT_COUNT) {
    play("powerUp");
    addScore(savedCount * 100, 50, 50);
  }

  // Game over check (all objects absorbed into center)
  const allTrapped = objects.every((obj) => obj.pos.distanceTo(centerPos) < 5);
  if (allTrapped) {
    end();
  }
}
```

**Step 2: Create Game Proposal JSON**

```bash
# Create tmp/prototypes/<slug>/proposed_game.json
mkdir -p tmp/prototypes/gravity_outpost
cat > tmp/prototypes/gravity_outpost/proposed_game.json <<'EOF'
{
  "slug": "gravity_outpost",
  "title": "GRAVITY OUTPOST",
  "description": "Push objects to safe zones using charged explosions while fighting gravity",
  "tags": ["player:multiple", "field:gravity", "weapon:explosion", "rule:physics", "obstacle:penalty"],
  "mechanics": ["explosion", "charge", "gravity", "timing"],
  "victoryCondition": "Save all objects by placing them in safe zones before they get trapped in center"
}
EOF
```

**Step 3: Execute Similarity Check**

```bash
npm run similarity-check -- tmp/prototypes/gravity_outpost/proposed_game.json

# Automatic judgment:
# - Over 70% â†’ âŒ Immediately reject, return to Phase 2
# - 40-70% â†’ âš ï¸ Caution level, ask human judgment
# - Under 40% â†’ âœ… Acceptable, proceed to next step
```

**Similarity Judgment Branching:**

```markdown
ã€Case A: Over 70% (Automatic Rejection)ã€‘
ðŸ¤– "Similarity check: 75% - Overlap with existing games too high"
ðŸ¤– "Returning to Phase 2 to strengthen differentiation elements"
â†’ Re-execute from Phase 2 Step 5 (Exclusion Filtering)

ã€Case B: 40-70% (Human Judgment)ã€‘
ðŸ¤– "Similarity check: 55% - Moderate similarity detected"
ðŸ¤– "Most similar game: [slug] (similarity 60%)"
ðŸ¤– "Main commonalities: [tag overlap, mechanic similarity]"
ðŸ¤ HUMAN DECISION:
âœ… "Acceptable range, sufficient uniqueness" â†’ Next step
ðŸ”„ "Need stronger differentiation" â†’ Return to Phase 2

ã€Case C: Under 40% (Automatic Approval)ã€‘
ðŸ¤– "Similarity check: 32% - Novelty assured, proceeding to next step"
â†’ Next step
```

**Step 4: Create Prototype Directory**

```bash
# Auto-generate with scaffold command (recommended)
npm run scaffold -- --slug gravity_outpost \
  --tags "player:multiple,field:gravity,weapon:explosion,rule:physics,obstacle:penalty" \
  --novelty-check

# Or manual creation
mkdir -p tmp/prototypes/gravity_outpost
cp tmp/games/gravity_outpost.js tmp/prototypes/gravity_outpost/game.js

# Important: Must create context.md (required input for novelty evaluation)
cat > tmp/prototypes/gravity_outpost/context.md <<'EOF'
# Game Context: gravity_outpost

- Tags: player:multiple, field:gravity, weapon:explosion, rule:physics, obstacle:penalty
- Categories: player, field, weapon, rule, obstacle
- Generated: 2025-01-09
- Description: Push objects to safe zones using charged explosions while fighting gravity
- Problem Category: Physics/Forces
- Core Verb: Charge explosion to repel objects
EOF
```

### ðŸ¤ HUMAN CHECKPOINT

**Feedback Collection Questions (Phase 3 Focus):**

```markdown
Please verify basic functionality:

ã€Comprehension Testã€‘

- Can you understand the game's purpose within 3 seconds?
- Is it clear what you should do?

ã€Achievability Testã€‘

- Can you reach the goal with button controls only?
- Are there any awkward or impossible aspects to the controls?

ã€Control Feel Testã€‘

- Is the response when pressing the button immediate and clear?
- Is the effect of holding (charging) easy to understand?
- Is the feedback from releasing (explosion) appropriate?

ã€Visual Feedback Testã€‘
Are the visual communication specifications designed in Phase 2 implemented?

- Problem recognition (clear danger zone, safe zones)
- Action feedback (explosion effects, charge display)
- Progress display (saved object count)
- Failure warning (warning when approaching center)

ã€Specific Feedback Examplesã€‘
âœ… Good: "Understood, interesting"
ðŸ”„ Needs Adjustment: "Movement too slow" â†’ Parameter adjustment
ðŸ”„ Needs Adjustment: "Explosion too weak" â†’ Parameter adjustment
ðŸ”„ Needs Adjustment: "Charge display hard to see" â†’ Visual adjustment
âŒ Problem: "Cannot reach goal" â†’ Logic review

Please provide specific feedback.
```

**Feedback-Driven Adjustment:**

```markdown
ã€Adjustment Cycle Exampleã€‘

ðŸ¤ HUMAN: "Object movement too slow, boring"
ðŸ¤– LLM: "Adjusting GRAVITY_STRENGTH from 0.1 â†’ 0.15"
[Code update]
ðŸ¤– LLM: "Please re-test"

ðŸ¤ HUMAN: "Now too fast, can't control"
ðŸ¤– LLM: "Adjusting GRAVITY_STRENGTH from 0.15 â†’ 0.12"
[Code update]

ðŸ¤ HUMAN: "Better. Want explosion force slightly stronger too"
ðŸ¤– LLM: "Adjusting SMALL_EXPLOSION_FORCE from 2 â†’ 2.5"
[Code update]

ðŸ¤ HUMAN: "Perfect. Proceed"
```

### âœ… COMPLETION CRITERIA

```markdown
â–¡ Crisp Game Library compliant code generation completed
â–¡ Balance parameters declared in const UPPER_SNAKE_CASE format
â–¡ proposed_game.json creation completed
â–¡ Similarity check execution completed (< 70% or human approval)
â–¡ Prototype directory creation completed
â–¡ context.md created (required input for novelty evaluation)
â–¡ Human basic functionality confirmation obtained
â–¡ Visual communication specification reflected in implementation
â–¡ Feedback-based adjustments completed (human satisfied)

â†’ If all met, proceed to Phase 4
```

---

## Phase 4: Validation and Balance Adjustment

**Purpose:** Perform quality evaluation and vulnerability diagnostics, adjust balance as needed
**Estimated Time:** 30-45 minutes
**Main Processing:** Basic validation, GA diagnostics, quality score calculation, cooperative evolution balance adjustment

### ðŸ¤– LLM AUTO-EXECUTE (Step 1: Basic Validation)

```bash
# Basic validation (syntax & style)
npm run verify-prototype -- --slug gravity_outpost --mode lint

# Example output:
# âœ… ESLint passed
# âœ… Required elements present (title, description, options, update)
# âœ… Coding style compliant (2-space indent, semicolons)
```

**Syntax Error Handling:**

```markdown
ã€Case A: No Errorsã€‘
âœ… Lint check passed â†’ Proceed to GA diagnostics

ã€Case B: Errors Detectedã€‘
ðŸ¤– "Syntax errors detected: [error details]"
ðŸ¤– "Attempting automatic fix"
[Code fix]
ðŸ¤– "Re-executing validation"
â†’ Iterate until errors resolved
```

### ðŸ¤– LLM AUTO-EXECUTE (Step 2: GA Diagnostics)

```bash
# GA optimization input pattern evaluation
npm run verify-prototype -- --slug gravity_outpost --mode ga

# Example output:
# GA Best Score: 450
# GA Survival Time: 38.5s
# Monotonous Best: 180 (HoldOnly)
# GA Resistance: Moderate (75 points)
# Technical Score: 85/100
# Design Score: 65/100
# Novelty Score: 78/100
# Overall Score: 76/100
```

**Diagnostic Result Interpretation:**

```markdown
ã€Quality Score Evaluationã€‘

- Technical Score (85): Good syntax accuracy, execution stability
- Design Score (65): Balance needs improvement (38.5s vs target 30-60s)
- Novelty Score (78): Novelty assured
- Overall Score (76): Overall good

ã€GA Resistance Evaluationã€‘

- GA Resistance: Moderate (75 points)
  â†’ 50-100 point range: Moderate vulnerability, adjustment recommended

ã€Normalized Score Evaluationã€‘

- Normalized GA score: 450/(450+180) = 0.71
- Normalized monotonous score: 180/(450+180) = 0.29
  â†’ Normalized monotonous score â‰¤ 0.5 and normalized GA score < 0.75
  â†’ Judgment: "Needs verification" (human judgment required)
```

### Diagnostic Result Branching Decision

```markdown
ã€Decision Flowchartã€‘

Normalized monotonous score > 0.5?
YES â†’ âŒ Needs improvement (vulnerability) â†’ Balance adjustment required
NO â†’ Next judgment

Normalized GA score > 0.75?
YES â†’ âœ… Ideal (skill-based) â†’ Proceed to Phase 5
NO â†’ âš ï¸ Needs verification â†’ Human judgment
```

### ðŸ¤ HUMAN CHECKPOINT (Diagnostic Result Judgment)

**Feedback Collection Questions:**

```markdown
Please review GA diagnostic results:

ã€Diagnostic Summaryã€‘

- GA Best Score: 450
- Monotonous Best: 180 (HoldOnly)
- Normalized GA score: 0.71 (71%)
- Normalized monotonous score: 0.29 (29%)
- GA Resistance: Moderate (75 points)

ã€Judgment Resultã€‘
Normalized monotonous score â‰¤ 0.5: âœ… Monotonous input not dominant
Normalized GA score 0.71: âš ï¸ Under 0.75, "needs verification"

ã€Questionsã€‘

1. Is this vulnerability level (Moderate) acceptable?

   - Is 2.5x score with skill-based play a sufficient difference?

2. Should balance adjustment be performed?

   - Target score: What would be appropriate? (Recommended: 100-150)
   - Target survival time: How many seconds appropriate? (Recommended: 30-60s)

3. Or should game design be reviewed?
   - Return to Phase 2 to strengthen differentiation elements?

ã€Response Optionsã€‘
âœ… "Acceptable range, proceed to Phase 5"
ðŸ”§ "Perform balance adjustment: target score 100, survival time 45s"
ðŸ”„ "Review design: [specific improvement plan]" â†’ Return to Phase 2
```

**Expected Human Response:**

```markdown
Example 1: "Perform balance adjustment: target score 100, survival time 45s"
â†’ To balance adjustment phase

Example 2: "Acceptable range, proceed to Phase 5 as is"
â†’ Skip to Phase 5

Example 3: "HoldOnly scoring 180 is problematic. Need adjustment"
â†’ To balance adjustment phase
```

### ðŸ¤– LLM AUTO-EXECUTE (Balance Adjustment: Only if Human Selected)

**Step 1: Parameter Extraction**

```bash
# Generate parameter extraction prompt
npm run extract-balance-params -- --slug gravity_outpost

# Output: tmp/prompts/extract_params_gravity_outpost.md
```

**Step 2: Generate balance_params.json**

```json
{
  "gameSlug": "gravity_outpost",
  "parameters": [
    {
      "path": "GRAVITY_STRENGTH",
      "currentValue": 0.1,
      "suggestedMin": 0.05,
      "suggestedMax": 0.3,
      "description": "Strength of gravitational pull toward center",
      "balanceImpact": "high",
      "location": "line 15"
    },
    {
      "path": "SMALL_EXPLOSION_FORCE",
      "currentValue": 2,
      "suggestedMin": 1,
      "suggestedMax": 5,
      "description": "Force of small explosion on tap",
      "balanceImpact": "medium",
      "location": "line 16"
    },
    {
      "path": "CHARGE_RATE",
      "currentValue": 0.5,
      "suggestedMin": 0.3,
      "suggestedMax": 1.5,
      "description": "Charge speed",
      "balanceImpact": "medium",
      "location": "line 17"
    },
    {
      "path": "MAX_CHARGE_RADIUS",
      "currentValue": 30,
      "suggestedMin": 20,
      "suggestedMax": 50,
      "description": "Maximum charge range",
      "balanceImpact": "high",
      "location": "line 18"
    }
  ]
}
```

**Step 3: Execute Cooperative Evolution**

```bash
# Execute with target metrics specified by human
npm run balance-game -- --slug gravity_outpost \
  --target-score 100 \
  --target-time 45 \
  --max-iterations 5 \
  --player-gens 30 \
  --balance-gens 20

# Process:
# 1. Player GA: Evolve high-score input patterns with fixed parameters
# 2. Evaluate: Calculate difference between achieved score/time and target
# 3. Balance GA: Adjust parameters to approach target metrics by optimizing score gap
#    - Fitness = gapWeight * -scoreGap + scoreWeight * scoreDiff + timeWeight * timeDiff
#    - gapWeight: 2.0 promotes skill-based play
#    - Auto-evaluate monotonous input tests (NoInput/HoldOnly/SpamPress)
# 4. Convergence check: If difference below threshold, finish; otherwise return to 1

# Output:
# - tmp/prototypes/gravity_outpost/adjusted_game.js
# - tmp/prototypes/gravity_outpost/adjusted_params.json
```

**Step 4: Re-diagnose After Adjustment**

```bash
# Vulnerability evaluation of adjusted game
npm run verify-prototype -- --slug gravity_outpost \
  --file tmp/prototypes/gravity_outpost/adjusted_game.js \
  --mode ga

# Example output:
# GA Best Score: 385
# Monotonous Best: 95 (HoldOnly)
# GA Resistance: Low (45 points) â† Improved from Moderate (75)
# Technical Score: 85/100
# Design Score: 78/100 â† Improved from 65
# Overall Score: 81/100 â† Improved from 76
```

**Adjustment Result Evaluation:**

```markdown
ã€Vulnerability Change Evaluationã€‘
Before adjustment: Moderate (75 points)
After adjustment: Low (45 points)
â†’ âœ… Improvement (Moderate to Low transition)

ã€Acceptance Criteriaã€‘
âœ… Maintained: Same Resistance category
âœ… Improved: Transition to better category
âŒ Degraded: Transition to worse category â†’ Re-adjust or redesign game

Current: âœ… Improvement confirmed
```

### ðŸ¤ HUMAN CHECKPOINT (Post-Adjustment Confirmation)

**Feedback Collection Questions (Phase 4 Focus):**

```markdown
Please test the game after balance adjustment:

ã€Core Mechanics Understandingã€‘

- Can you understand the unique system (charged explosion vs gravity) behavior?
- Are the mechanic interactions interesting?

ã€Difficulty Evaluationã€‘

- Is the difficulty appropriate? (Too easy/too hard)
- Is the learning curve natural?

ã€Parameter Feelã€‘
Verify feel of adjusted parameters:

- Is gravity strength appropriate? (Too fast/too slow)
- Is explosion force appropriate? (Too strong/too weak)
- Is charge speed appropriate? (Too fast/too slow)

ã€Risk-Reward Balanceã€‘

- Do you feel it's worth taking risks?
- Is the balance between safe and adventurous strategies attractive?

ã€Specific Feedback Examplesã€‘
âœ… "Perfect, proceed"
ðŸ”„ "Gravity still too strong" â†’ Parameter re-adjustment
ðŸ”„ "Charging too slow" â†’ Parameter re-adjustment
âŒ "Too monotonous" â†’ Return to Phase 2

Will repeat adjustments until satisfied. Please provide specific feedback.
```

**Iterative Adjustment Cycle:**

```markdown
ã€Adjustment Cycleã€‘
Repeat until satisfied:

1. ðŸ¤ HUMAN: Specific feedback
   Example: "Gravity still a bit strong"

2. ðŸ¤– LLM: Manually adjust adjusted_params.json
   GRAVITY_STRENGTH: 0.12 â†’ 0.10

3. ðŸ¤– LLM: Inject into adjusted_game.js
   [Use dynamic_game_injector.js]

4. ðŸ¤– LLM: Re-diagnose
   npm run verify-prototype --file adjusted_game.js --mode ga

5. ðŸ¤– LLM: Present results
   "Adjusted GRAVITY_STRENGTH to 0.10. Please re-test"

6. ðŸ¤ HUMAN: Evaluate
   "Better" or "Still needs adjustment"

â†’ Repeat until human satisfied
```

### âœ… COMPLETION CRITERIA

```markdown
â–¡ Lint validation completed (no syntax errors)
â–¡ GA diagnostics execution completed
â–¡ Quality score calculation completed
â–¡ GA Resistance evaluation completed
â–¡ Human judgment obtained (accept or perform adjustment or review design)

ã€If Balance Adjustment Performedã€‘
â–¡ Parameter extraction completed
â–¡ balance_params.json generation completed
â–¡ Cooperative evolution execution completed
â–¡ adjusted_game.js generation completed
â–¡ Post-adjustment re-diagnosis completed
â–¡ Vulnerability change evaluation completed (maintained/improved/degraded)
â–¡ Human balance confirmation obtained (iterate until satisfied)

ã€Acceptance Criteriaã€‘
â–¡ GA Resistance: Low maintained or Moderateâ†’Low improvement or human accepts
â–¡ Quality scores: Each item meets criteria or human satisfied
â–¡ Normalized scores: Normalized monotonous score â‰¤ 0.5 or human accepts

â†’ If all met, proceed to Phase 5
```

---

## Phase 5: Final Validation and Completion Approval

**Purpose:** Perform comprehensive evaluation and obtain final completion approval
**Estimated Time:** 10 minutes
**Main Processing:** Comprehensive evaluation, novelty metrics calculation, comprehensive report generation, metrics recording

### ðŸ¤– LLM AUTO-EXECUTE

**Step 1: Execute Comprehensive Evaluation**

```bash
# Comprehensive evaluation (lint + sim + novelty metrics)
npm run verify-prototype -- --slug gravity_outpost --mode full

# Example output:
# === Lint Check ===
# âœ… ESLint passed
# âœ… Required elements present
# âœ… Coding style compliant
#
# === Simulation Check ===
# âœ… Game runs without crash
# âœ… Input response confirmed
# âœ… Game over condition working
# âœ… Average survival time: 42.3s
#
# === Novelty Metrics ===
# Tag Novelty Ratio: 0.65 (threshold: 0.3) âœ…
# Mechanical Coherence: 0.82 (threshold: 0.7) âœ…
# Estimated Code Originality: 0.76 (threshold: 0.7) âœ…
# Overall Novelty: 0.74 (threshold: 0.5) âœ…
#
# === Quality Scores ===
# Technical Score: 85/100
# Design Score: 78/100
# Novelty Score: 78/100
# Overall Score: 81/100
```

**Step 2: Generate Comprehensive Report**

```markdown
# Comprehensive Evaluation Report: gravity_outpost

Generated: 2025-01-09 14:30:00

## Tag Information

- Tags: player:multiple, field:gravity, weapon:explosion, rule:physics, obstacle:penalty
- Categories: 5 (player, field, weapon, rule, obstacle)
- Tag Novelty Ratio: 0.65

## Problem-Solution Structure

- Problem Category: Physics/Forces
- Player wants to: Place multiple objects in safe zones
- Current obstacle: Gravity pulls them toward center
- Solution: Push back with charged explosion, timing adjustment

## Technical Quality

- Technical Score: 85/100
  - Syntax accuracy: 40/40
  - Execution stability: 30/30
  - Vulnerability resistance: 15/30 (GA Resistance: Low 45 points)

## Design Quality

- Design Score: 78/100
  - Game balance: 45/50 (survival time 42.3s, within target 30-60s range)
  - Difficulty appropriateness: 23/30 (provisional full score)
  - Control feel: 10/20 (provisional half)

## Novelty

- Novelty Score: 78/100
  - Tag Novelty Ratio: 0.65 (new tag pair rate 65%)
  - Mechanical Coherence: 0.82 (good tag compatibility)
  - Estimated Code Originality: 0.76 (high code originality)

## Overall Evaluation

- Overall Score: 81/100
- Judgment: GOOD (70-85 point range)

## Differentiation Elements

- Victory condition: "Push back with explosions" (not existing "collect with attraction")
- Control method: "Charge-based timed explosion" (not existing "continuous explosions")
- Game loop: "Placement optimization" (not existing "enemy elimination")

## Balance Adjustment History

- Initial diagnosis: GA Resistance Moderate (75 points)
- Adjustment performed: Cooperative evolution 5 iterations
- After adjustment: GA Resistance Low (45 points)
- Improvement confirmed: âœ…

## Recommendations

- Sufficient quality achieved in current state
- Metrics recording recommended after final approval
```

### ðŸ¤ HUMAN FINAL VALIDATION

**Feedback Collection Questions (Phase 5 Focus):**

```markdown
Please provide final experience evaluation:

ã€Replay Motivationã€‘

- Do you want to play this game repeatedly?
- Does it create an "one more time" feeling?
- Can you feel improvement after playing several times?

ã€Remaining Issues Confirmationã€‘

- Are there any remaining balance or control issues?
- Are there any visually unclear parts?
- Is the game over condition fair and clear?

ã€Completeness Evaluationã€‘

- Can you call this state "complete"?
- Has it reached a level where others could play it?

ã€Comprehensive Report Reviewã€‘
Please review the presented comprehensive evaluation report:

- Overall Score: 81/100
- Are each scores reasonable?
- Are differentiation elements clear?

ã€Response Optionsã€‘
âœ… "Approved & Complete" â†’ Record metrics, save logs
ðŸ”„ "Minor adjustment: [specific content]" â†’ Return to Phase 4
âŒ "Fundamental problem: [reason]" â†’ Return to Phase 2 or Phase 1 (human specifies)

Please provide final judgment.
```

**Final Approval Decision:**

```markdown
ã€Processing Based on Human Responseã€‘

âœ… Approved & Complete:
â†’ Proceed to metrics recording and log saving

ðŸ”„ Minor adjustment:
Example: "Want charge sound emphasized more"
â†’ ðŸ¤– Execute adjustment
â†’ ðŸ¤– Re-present
â†’ ðŸ¤ Re-evaluate
(Repeat until satisfied)

âŒ Fundamental problem:
Example: "Still too similar to existing games"
â†’ Return to Phase 2 (Creative Synthesis)

Example: "Contradiction in problem-solution logic"
â†’ Return to Phase 1 (Problem-Solution Structuring)
```

### ðŸ¤– LLM AUTO-EXECUTE (Post-Approval Recording)

**Step 1: Record Metrics**

```csv
# Append to knowledge/metrics/tag_combo_history.csv

date,tags,slug,outcome,notes,ga_best_score,ga_resistance,technical_score,design_score,novelty_score,overall_score
2025-01-09,"player:multiple|field:gravity|weapon:explosion|rule:physics|obstacle:penalty",gravity_outpost,pass,mode=full+balance_adjusted,385,Low,85,78,78,81
```

**Step 2: Save Log**

```bash
# Generate knowledge/logs/20250109-gravity_outpost.md

cat > knowledge/logs/20250109-gravity_outpost.md <<'EOF'
# Game Generation Log: gravity_outpost

Generated: 2025-01-09 14:30:00
Total time: 115 minutes

## Phase Summary

### Phase 0: Tag Selection and Initial Validation (10 min)
- Selected tags: player:multiple, field:gravity, weapon:explosion, rule:physics, obstacle:penalty
- Categories: 5
- Novelty score: 0.65
- Human approval: âœ…

### Phase 1: Problem-Solution Structuring (12 min)
- Problem category: Physics/Forces
- Solution: Charged explosion counters gravity
- Human approval: âœ… (approved on 1st attempt)

### Phase 2: Creative Synthesis and Novelty Assurance (18 min)
- Differentiation elements: Push back with explosions, charge-based, placement optimization
- Warning signs: 0
- Human approval: âœ… (approved on 1st attempt)

### Phase 3: Implementation and Prototyping (25 min)
- Similarity: 32% âœ…
- Adjustment count: 3 (movement speed, explosion force, charge speed)
- Human approval: âœ…

### Phase 4: Validation and Balance Adjustment (40 min)
- Initial GA diagnosis: Moderate (75 points)
- Balance adjustment: Performed (cooperative evolution 5 iterations)
- Post-adjustment GA diagnosis: Low (45 points)
- Adjustment count: 2 (gravity strength fine-tuning)
- Human approval: âœ…

### Phase 5: Final Validation and Completion Approval (10 min)
- Overall Score: 81/100
- Human approval: âœ…

## Final Deliverables

### Files
- tmp/games/gravity_outpost.js
- tmp/prototypes/gravity_outpost/game.js
- tmp/prototypes/gravity_outpost/adjusted_game.js (balance-adjusted version)
- tmp/prototypes/gravity_outpost/proposed_game.json
- tmp/prototypes/gravity_outpost/context.md
- tmp/prototypes/gravity_outpost/balance_params.json
- tmp/prototypes/gravity_outpost/adjusted_params.json

### Metrics
- Technical Score: 85/100
- Design Score: 78/100
- Novelty Score: 78/100
- Overall Score: 81/100
- GA Resistance: Low (45 points)

## Learning Points

### Success Factors
- Human problem category indication in Phase 0 was accurate
- Logical problem-solution structure approved on 1st attempt in Phase 1
- Feedback-driven adjustment in Phase 3 was efficient (converged in 3 iterations)
- Cooperative evolution in Phase 4 significantly improved GA Resistance (75â†’45 points)

### Improvement Areas
- Balance adjustment in Phase 4 took 40 minutes (target 30 minutes)
  - Reason: Required 2 cycles of fine-tuning after cooperative evolution
  - Countermeasure: Set narrower recommended range in balance_params.json

### Implications for Next Time
- Physics/Forces category games work well with cooperative evolution
- Charge-type mechanics tend to require more adjustment iterations
- Finalizing visual feedback design early smooths later processes

EOF
```

**Step 3: Organize Deliverables**

```bash
# Organize prototype directory
ls tmp/prototypes/gravity_outpost/
# Output:
# - game.js (initial implementation)
# - adjusted_game.js (balance-adjusted version - recommended)
# - proposed_game.json
# - context.md
# - balance_params.json
# - adjusted_params.json
# - verify_report.md (verification report)
```

### âœ… COMPLETION CRITERIA

```markdown
â–¡ Comprehensive evaluation execution completed (lint + sim + novelty metrics)
â–¡ Novelty metrics calculation completed (Tag Novelty, Mechanical Coherence, Code Originality)
â–¡ Quality score calculation completed (Technical, Design, Novelty, Overall)
â–¡ Comprehensive report generation completed
â–¡ Human final approval obtained
â–¡ knowledge/metrics/tag_combo_history.csv updated
â–¡ knowledge/logs/<YYYYMMDD>-<slug>.md generated
â–¡ Deliverables organized (tmp/prototypes/<slug>/)

ã€Final Quality Criteriaã€‘
â–¡ Overall Novelty >= 0.5 (novelty threshold)
â–¡ Overall Score >= 60 (minimum quality standard)
â–¡ GA Resistance: Low or Moderate (human accepts)
â–¡ Human judges "complete"

â†’ If all met, complete
```

---

## Troubleshooting

### Similarity Check Repeatedly Exceeds 70%

**Symptom:** Similarity exceeds 70% 3+ times consecutively in Phase 3

**Solution:**

```markdown
1. Return to Phase 0 and completely re-select tag combination
2. Strengthen exclusion filtering in Phase 2:
   - Explicitly exclude more existing patterns
   - Add 2+ differentiation elements
   - Consider differentiation at visual representation level
3. Request creative breakthrough from human:
   - "With this tag combination, is there an interesting use not in existing games?"
```

### Balance Adjustment Does Not Converge

**Symptom:** Cooperative evolution in Phase 4 exceeds 10 iterations without reaching target

**Solution:**

```markdown
1. Confirm target metrics validity with human:
   - "Target score 100 may be too high. Lower to 80?"
2. Expand recommended range in balance_params.json:
   - After confirming with human, widen suggestedMin/Max
3. Fundamental review of game design:
   - Return to Phase 2, adjust mechanics
   - Possible structural problem not solvable by simple numerical adjustment
```

### Human Feedback Is Vague

**Symptom:** Feedback lacking specificity like "something's off" or "not quite right"

**Solution:**

```markdown
1. Narrow down with specific questions:
   - "Which is the problem: speed/timing/difficulty?"
   - "At what point do you feel the problem: first 10 seconds/midgame/endgame?"
2. Clarify through comparison:
   - "Compared to previous adjustment, is it better or worse?"
3. Step-by-step confirmation:
   - "First, is control feel okay? (Yes/No)"
   - "Is difficulty appropriate? (Yes/No)"
   - "Are there visually unclear parts? (Yes/No)"
```

### Frequent Rollbacks Between Phases

**Symptom:** Large rollbacks like Phase 3â†’Phase 1, Phase 4â†’Phase 2 occur frequently

**Solution:**

```markdown
1. Strictly apply completion criteria for each phase:
   - Do not proceed until obtaining clear "approval" from human
   - Resolve ambiguities immediately
2. Strengthen validation in Phase 1 and Phase 2:
   - Perform logical walkthrough in more detail
   - Don't miss warning signs
3. Request early review from human:
   - Upon Phase 1 completion: "Really okay to proceed as is?"
   - Upon Phase 2 completion: "Final confirmation before implementation"
```

---

## Reference Documents

### Technical Foundation (Detailed Specifications)

- `novelty_game_generation.md`: Novelty assurance mechanisms, tag selection, similarity check
- `game_evaluation_system.md`: Evaluation criteria, validation modes, balance adjustment system

### Implementation Reference

- `crisp-game-lib-guide.md`: Crisp Game Library API, patterns, best practices
- `knowledge/snippets/README.md`: Tag snippet notation and operational rules

### Collaboration Guidelines

- `collaboration_guidelines.md`: Feedback Collection Templates, best practices
- `CLAUDE.md`: Overall project operational policy, coding conventions

### Data & Configuration

- `knowledge/tag_categories_enhanced.csv`: Tag roles, interactions, complexity information
- `knowledge/prompts/main_v2_novelty.md`: Reference prompt templates
- `knowledge/metrics/tag_combo_history.csv`: Past generation history and metrics
