# One-Button Game Design Workflow Guide (Human-LLM Collaborative Version)

This guide provides a systematic 5-phase workflow for designing games that are fun, understandable, and innovative through strategic human-LLM collaboration.

**IMPORTANT: The themes, verbs, methods, mechanics, types, genres, etc. mentioned in this guide should be treated as examples only. Feel free to think broadly and creatively beyond the content presented in this guide.**

**Diversity Encouragement: Explore diverse physical concepts like light, magnetism, growth, and other intuitive phenomena. The goal is to create varied, innovative experiences that players can immediately understand and enjoy.**

## ü§ù Human-LLM Collaboration Protocol

**Strategic Collaboration:**

- **LLM Strengths**: Systematic processing, template completion, constraint checking, pattern recognition
- **Human Strengths**: Intuitive validation, experience judgment, ambiguity resolution, creative feedback
- **Collaboration Triggers**: Uncertainty detection, constraint violations, complexity issues, final validation

**Session Time**: 35-50 minutes | LLM autonomous: ~70% | Human validation: ~30%

**Essential Human Checkpoints:**

1. **Phase 0**: Theme concreteness and appeal validation
2. **Phase 1**: Simple solution logic validation
3. **Phase 2**: Experience walkthrough approval
4. **Phase 3**: Implementation readiness confirmation

**Collaboration Execution:**

```markdown
ü§ñ LLM AUTO-EXECUTE: Template completion, constraint checking, systematic processing
ü§ù HUMAN CHECKPOINT: Problem clarity, solution logic, complexity assessment, final validation
üö´ FORBIDDEN: Starting with "interesting mechanics" before problem definition
‚úÖ REQUIRED: Problem ‚Üí Solution ‚Üí Innovation ‚Üí Experience ‚Üí Implementation flow
```

## Workflow Overview

**Complete each phase in order. Each phase validates and refines previous phases.**

| Phase | Purpose                             | Input                                   | Output                           | Completion Check                                              |
| ----- | ----------------------------------- | --------------------------------------- | -------------------------------- | ------------------------------------------------------------- |
| 0     | Concrete Theme Inspiration (Human-Validated) | Theme categories                        | Selected concrete theme     | ‚úÖ Concrete theme selected + Human validation obtained + Clear constraints identified |
| 1     | Simple Problem-Solution Design | Problem categories + Theme | Clear problem-solution pairs | ‚úÖ Problem defined + Simple verb + Logic validated |
| 2     | Player Experience Integration       | Simple, clear mechanics              | Engaging, understandable game    | ‚úÖ Conceptual walkthrough + User feedback                     |
| 3     | Final Validation & Documentation    | Complete experience                     | Implementation-ready spec        | ‚úÖ All warning signs checked + Spec complete                  |

---

## Phase 0: Theme Inspiration (Automated)

**Phase Input:** Theme categories (provided below)
**Phase Output:** Selected concrete, relatable theme to guide creative thinking
**Completion Criteria:** ‚úÖ Concrete professional/historical theme selected ‚úÖ Human validation obtained ‚úÖ Theme provides clear constraints and universal appeal

### ‚ö†Ô∏è Phase 0 Execution Protocol

**EXECUTION ORDER:**

```markdown
ü§ñ LLM AUTO: Theme category selection ‚Üí Theme generation ‚Üí 3-stage validation ‚Üí Best theme selection
ü§ù HUMAN: Theme appeal confirmation ‚Üí Alternative preference ‚Üí Final approval
‚ö†Ô∏è IMPORTANT: Theme serves as INSPIRATION only, not as design constraint
‚ö†Ô∏è CRITICAL: Problem-solution logic always takes priority over theme adherence
‚ö†Ô∏è NEW: Concrete professions/scenarios preferred over abstract concepts
```

### 0.1 Theme Category Selection

**LLM automatically generates 3-5 themes from across all categories below, prioritizing concrete and relatable experiences:**

```markdown
üèõÔ∏è **Historical Professions & Roles**
Examples: Lighthouse keeper, Telegraph operator, Blacksmith, Town crier, Mail carrier, Night watchman
Effect: Concrete professional experiences with clear responsibilities, time-period constraints, and job-specific limitations

üåç **Specific Places & Facilities**
Examples: Library operations, Museum security, Observatory work, Dam control room, Radio station, Fire tower
Effect: Real-world locations with specific operational constraints, environmental factors, and facility-based responsibilities

üìö **Historical Events & Scenarios**
Examples: Apollo moon landing, Medieval castle siege, Early telephone switching, 1960s computer operation, Ship navigation pre-GPS
Effect: Time-period constraints, technological limitations, urgency, and historical context create natural game constraints

üîß **Everyday Tools & Machines**
Examples: Analog watch repair, Manual printing press, Record player adjustment, Old-style camera operation, Hand-crank drill
Effect: Tactile understanding, precision requirements, familiar mechanical interactions with clear operational constraints

üé™ **Cultural Events & Performances**
Examples: Circus preparation, Orchestra tuning, Theater lighting, Festival coordination, Art gallery setup, Wedding planning
Effect: Performance pressure, timing requirements, coordination challenges, and perfectionism constraints

‚ö° **Everyday Natural Phenomena**
Examples: Surface tension effects, Plant growth cycles, Ice melting patterns, Sand flow dynamics, Steam condensation, Water pressure
Effect: Daily-life physics experiences, intuitive understanding, natural timing constraints

üéÆ **Classic Game Reinterpretation**
Examples: Pac-Man maze navigation, Billiards angle calculation, Chess strategic thinking, Arcade timing challenges
Effect: Provides familiar interaction patterns to reinterpret with one-button constraint

üî¨ **Professional Domain Basics**
Examples: Medical equipment calibration, Laboratory sample preparation, Engineering measurement, Cooking temperature control
Effect: Suggests systematic processes, specialized knowledge applications, and precision requirements
```

### 0.2 Theme Generation and Selection

```markdown
LLM AUTOMATED PROCESS:

1. **Theme Generation**: Create 3-5 specific themes from across ALL categories above
2. **3-Stage Selection Process**:

   **Stage 1: Concreteness Check**
   ‚úÖ Represents a concrete profession, place, or historical scenario
   ‚úÖ Universally recognizable and relatable (avoid cultural specificity)
   ‚úÖ Can be visualized and understood by anyone

   **Stage 2: Appeal Assessment**
   ‚úÖ Engaging enough to make people curious ("I'd like to try that")
   ‚úÖ Unexplored in game themes (fresh without being obscure)
   ‚úÖ Can be explained compellingly in one sentence

   **Stage 3: Constraint Clarity**
   ‚úÖ Has domain-specific constraints and responsibilities
   ‚úÖ Natural limitations that align with one-button gameplay
   ‚úÖ Clear cause-and-effect relationships

3. **Final Selection**: Pick ONE theme that passes all three stages as creative inspiration
```

### 0.2.1 Human Validation Checkpoint

```markdown
ü§ù HUMAN VALIDATION REQUEST:
"I've selected [THEME] as the creative inspiration. Quick validation:

- Is this concrete and relatable enough?
- Does it sound engaging to you?
- Can you immediately imagine the constraints this profession/scenario would have?
- Would you prefer a different theme from these alternatives: [list other candidates]?"

HUMAN RESPONSE OPTIONS:
‚úÖ "Good choice, proceed" ‚Üí Continue to Phase 1
üîÑ "Try [alternative] instead" ‚Üí Use human suggestion
‚ùå "All seem abstract/boring" ‚Üí Generate new set with different approach
```

### 0.3 Theme Application Guidelines

```markdown
ENHANCED THEME USAGE PROTOCOL:

‚úÖ **CORRECT Usage**:

- Use theme to inspire problem category selection based on profession-specific challenges
- Let theme suggest natural environmental constraints (workplace limitations, tool restrictions, time pressure)
- Allow theme to guide visual and conceptual metaphors rooted in real-world experience
- Reference theme when choosing specific verbs and mechanics that reflect actual job duties
- Leverage universal recognition of the profession/scenario for immediate player understanding

‚ùå **INCORRECT Usage**:

- Force all mechanics to literally recreate every aspect of the profession
- Abandon good problem-solution logic for theme authenticity
- Add complexity just to include more profession-specific details
- Use theme as excuse for violating one-button constraint
- Choose themes that require cultural knowledge to understand

üéØ **ENHANCED THEME INTEGRATION PRINCIPLE**:
"Concrete themes inspire relatable problems, universal constraints enable accessible solutions"

üí° **NEW THEME QUALITY CHECK**:
"Can someone immediately picture this job/scenario and understand why it would be challenging?"
```

**‚è≠Ô∏è Proceed to Phase 1 with selected theme as creative reference**

---

## Phase 1: Simple Problem-Solution Design

**Phase Input:** Problem categories + Selected theme (from Phase 0)
**Phase Output:** Clear problem-solution pairs with simple, understandable mechanics
**Completion Criteria:** ‚úÖ Problem category selected, ‚úÖ Problem template completed, ‚úÖ Simple verb applied, ‚úÖ Solution logic validated, ‚úÖ Goal achievement path clear

### ‚ö†Ô∏è Phase 1 Execution Protocol

**EXECUTION ORDER:**

```markdown
ü§ñ LLM AUTO: Theme-informed problem category selection ‚Üí Template completion
ü§ù HUMAN: Problem validation ‚Üí Solution logic confirmation
ü§ñ LLM AUTO: Verb application ‚Üí Control design ‚Üí Goal setting
```

### 1.1 Problem Definition (Steps A-B)

#### Step A: Theme-Informed Problem Category Selection

**Reference selected theme and select ONE problem category that resonates:**

```markdown
PROBLEM CATEGORIES:
‚ñ° **Movement/Navigation**: Cannot reach location due to obstacle/constraint
‚ñ° **Resource/Collection**: Must collect/use resource but constraint prevents efficiency
‚ñ° **Timing/Coordination**: Must coordinate action with moving element but limitation makes synchronization difficult
‚ñ° **Information/Visibility**: Cannot perceive critical information due to obstruction
‚ñ° **State/Balance**: Must maintain beneficial state while avoiding harmful state
‚ñ° **Physics/Forces**: Must overcome/manipulate physical force but natural law prevents direct control
‚ñ° **Pattern/Signal**: Must recognize/create/transmit pattern but interference obscures communication
```

#### Step B: Problem Template Completion

```markdown
SELECTED THEME: [Theme from Phase 0]
SELECTED CATEGORY: [Category from Step A]

Player wants to: [Specific goal - consider theme context]
Current obstacle: [What prevents this goal - may be theme-inspired]
Environmental constraint: [Why normal methods don't work - can reflect theme]

ü§ù HUMAN CHECKPOINT:
"Does this problem make sense as an interesting game challenge?
Does the theme enhance understanding without adding complexity?"
```

### 1.2 Simple Solution Design (Steps C-D)

**KEY PRINCIPLE: Maintain 3-second rule clarity above all else**

#### Step C: Simple and Effective Verb Selection

**STREAMLINED PROCESS: Clear mechanics with light innovation**

```markdown
STAGE 1: BASELINE VERB IDENTIFICATION
- Identify obvious/expected verb for the defined problem
- REVERSE CHECK: "Will this basic verb solve [obstacle] to achieve [goal]?"

BASELINE VERB CANDIDATES:
- Basic: Push, pull, rotate, stop, launch, release, activate, charge, aim, time
- Simple variations: Hold to charge, tap to release, time the action

STAGE 2: LIGHT IMPROVEMENT (3-SECOND RULE MAINTAINED)
- Keep the basic verb but add ONE simple twist that enhances engagement
- Examples:
  - "Push" ‚Üí "Push with timing" (timing adds strategy)
  - "Launch" ‚Üí "Charge and launch" (charging adds preparation)
  - "Release" ‚Üí "Release at peak moment" (timing adds skill)

**Guidelines for Light Innovation:**
- ‚úÖ Must be instantly understandable (3-second rule)
- ‚úÖ Should solve the core problem more effectively
- ‚úÖ Can add ONE strategic element (timing, charging, rhythm)
- ‚ùå No complex physics or multi-step processes
- ‚ùå No abstract concepts requiring explanation

STAGE 3: ONE-BUTTON COMPATIBILITY CHECK
- Verify selected verb works with press/hold/release only
- Ensure no hidden directional or positional input needed
- Confirm 3-second rule compliance
```

#### Step D: Simple Problem-Solution Logic Validation

```markdown
SIMPLE VALIDATION REQUIREMENTS:
‚ñ° Does the verb directly address the defined problem?
‚ñ° Is the connection clear: Problem ‚Üí Simple Solution ‚Üí Goal Achievement?
‚ñ° Can new player understand WHY this solution works within 3 seconds?
‚ñ° Does the solution respect the environmental constraint?
‚ñ° Is the mechanic immediately understandable and engaging?

ü§ù HUMAN CHECKPOINT:
"Does this simple problem-solution logic make sense and feel fun?"

- Problem: [specific obstacle]
- Simple Solution: [clear verb with light innovation]
- Logic: [why this solution works]
- 3-Second Test: [can new player understand instantly?]
```

### 1.3 Control Design (Step E)

#### Step E: Input-to-Output Mapping

```markdown
DEFINE EXACTLY:
Press (Tap): [Specific immediate action]
Hold (1-3 seconds): [Specific continuous action or parameter change]
Release (after hold): [Specific action execution or state change]

CONSTRAINT VALIDATION:
‚ñ° Can this be achieved with ONLY press/hold/release?
‚ñ° No position selection, directional input, or multiple inputs required?
‚ñ° Player can achieve goal using only these inputs?

ü§ù HUMAN SIMULATION:
"Try to 'play' this for 30 seconds using only press/hold/release.
Does anything feel impossible or require hidden inputs?"
```

### 1.4 Goal and Risk Setting (Step F)

```markdown
GOAL DEFINITION:

- Goal = Solution to the defined player problem
- Success = Problem resolved through designed mechanics
- Clear visual/spatial relationship between problem and goal

RISK DESIGN:

- Risks emerge from attempts to solve the core problem
- Failure = Problem becomes worse or new problems emerge
- Recovery = Learning better problem-solving strategies
```

**‚è≠Ô∏è Proceed to Phase 2 only after Phase 1 completion criteria are met**

---

## Phase 2: Player Experience Integration

**Phase Input:** Simple, clear mechanics from Phase 1
**Phase Output:** Engaging, understandable complete game experience
**Completion Criteria:** ‚úÖ Conceptual walkthrough completed, ‚úÖ User feedback obtained, ‚úÖ Experience validated

### 2.1 Conceptual Walkthrough (Replaces Impossible Simulation)

**Critical Replacement:** Since numerical simulation is impossible without parameters, use logical validation instead

#### Conceptual Walkthrough Process

**Instead of "30-second simulation," perform logical walkthrough:**

```markdown
WALKTHROUGH REQUIREMENTS:
‚ñ° Describe player's logical action sequence using only "press", "hold", "release"
‚ñ° Verify each action logically connects to next game state
‚ñ° Confirm goal achievement is logically possible
‚ñ° Check that no "impossible" actions are required

EXAMPLE WALKTHROUGH:
Start: Player faces the defined problem (cannot reach high platform)
Action 1: Player presses ‚Üí applies solution mechanic (gravity change)
Result 1: Game state changes (gravity direction shifts)
Action 2: Player holds ‚Üí modifies solution parameter (gravity strength)
Result 2: Effect scales appropriately (stronger gravity pull)
Action 3: Player releases ‚Üí executes solution (gravity applied)
Result 3: Problem resolves (player reaches platform)
End: Goal achieved through logical problem-solution chain

VALIDATION CHECK:
‚ñ° Every action uses only press/hold/release? ‚úÖ
‚ñ° Goal logically achievable? ‚úÖ
‚ñ° No directional input required? ‚úÖ
‚ñ° No position selection required? ‚úÖ
‚ñ° Problem-solution logic maintained? ‚úÖ
```

#### Impossible Action Detection

```markdown
RED FLAGS - If any appear, return to Phase 1:
‚ñ° "Player aims" ‚Üí How? One button cannot aim
‚ñ° "Player chooses location" ‚Üí How? One button cannot select positions  
‚ñ° "Player decides between options" ‚Üí How? One button cannot make binary choices
‚ñ° Walkthrough requires information not available to player
‚ñ° Solution mechanics don't actually solve the defined problem

If ANY red flag appears, the design is fundamentally flawed.
```

### 2.2 User Feedback Integration (FLEXIBLE APPROACH)

**Multiple validation options based on available resources:**

#### Option A: Actual User Testing (Preferred)

**Ask users (colleagues, friends) these specific questions:**

```markdown
Understanding Test:

1. "I'll describe a game concept. Tell me what you think the player does."
   [Describe your problem-solution concept in 2-3 sentences]

2. "What do you think happens when the player presses the button?"
   [Listen for understanding of your core mechanic]

3. "What do you think the goal is, and how would you achieve it?"
   [Verify problem-solution logic is clear]

4. "Does this sound fun to you? Why or why not?"
   [Check engagement level]

Pass Criteria:
‚ñ° User understands the problem the player faces
‚ñ° User understands how button press helps solve it
‚ñ° User sees logical connection between action and goal
‚ñ° User expresses interest or curiosity
```

#### Option B: Human Proxy Testing (Alternative)

```markdown
ü§ù HUMAN PROXY VALIDATION REQUEST:
"I'll describe the game concept. Please respond as if you're hearing it for the first time:
[Concept description]

What do you think the player does?
What happens when they press the button?
What's the goal and how would you achieve it?
Does this sound fun? Why or why not?"

EVALUATION CRITERIA:
‚ñ° Human understands concept immediately
‚ñ° Human can explain mechanics back correctly
‚ñ° Human sees clear connection between action and goal
‚ñ° Human expresses genuine interest or asks follow-up questions
```

#### Option C: LLM Simulation with Human Oversight (Fallback)

```markdown
ü§ñ LLM SIMULATED RESPONSES:
[LLM generates typical user responses based on concept clarity]

ü§ù HUMAN VALIDATION REQUEST:
"I'll simulate typical user responses. Please confirm if these seem realistic:
[Simulated responses]
Do these responses indicate good understanding and engagement?"

HUMAN EVALUATION:
‚úÖ "Responses seem realistic and positive" ‚Üí Proceed
üîÑ "Some responses seem unrealistic" ‚Üí Refine concept
‚ùå "Responses indicate confusion" ‚Üí Return to Phase 2
```

#### Response-Based Refinement

```markdown
Common User Responses ‚Üí Refinements Needed:

"I don't understand what I'm supposed to do" ‚Üí Problem definition unclear
"How do I control where things go?" ‚Üí Hidden directional input detected  
"That sounds complicated" ‚Üí 3-second rule violation
"Why can't I just [normal solution]?" ‚Üí Problem constraints unclear
"That sounds boring" ‚Üí Innovation or engagement insufficient

If users don't understand within 3 explanation sentences, redesign needed.
```

**‚è≠Ô∏è Proceed to Phase 3 only after Phase 2 completion criteria are met**

---

## Phase 3: Final Validation & Documentation

**Phase Input:** Complete experience from Phase 2
**Phase Output:** Implementation-ready specification with all warning signs addressed
**Completion Criteria:** ‚úÖ All warning signs checked, ‚úÖ Final walkthrough validated, ‚úÖ Implementation specification complete

### 3.1 Distributed Warning Signs Check (COLLABORATIVE)

**Instead of single overwhelming check, warnings distributed throughout phases:**

#### Phase 1 Auto-Checks (LLM Handles Automatically)

```markdown
ü§ñ LLM AUTOMATED REJECTION CRITERIA:
One-Button Constraint Basics:
‚ñ° Description includes "player chooses", "player aims", "player selects"  
‚ñ° Requires position selection beyond press/hold/release timing
‚ñ° Multiple control schemes or input modes needed

Problem Definition Completeness:
‚ñ° Abstract expressions ("use," "utilize") cannot be concretized
‚ñ° Forces/actions needed for goal achievement don't exist in described system
‚ñ° Phenomena violating physics laws occur without basis

If ANY detected ‚Üí Automatic return to appropriate phase
```

#### Phase 1 Human-Assisted Checks

```markdown
ü§ù HUMAN EVALUATION REQUEST:
"Please check these potential issues with the design:

Simplicity Check:

- Can you understand the core mechanic within 3 seconds?
- Does the solution feel natural and intuitive?
- Is the theme helping or hindering understanding?

Engagement Check:

- Does this feel fun or just repetitive?
- Is there room for skill improvement?
- Would you want to play this more than once?

Please flag any concerns before we proceed."

HUMAN RESPONSE OPTIONS:
‚úÖ "No issues detected" ‚Üí Proceed
üîÑ "Some concerns" ‚Üí Human provides specific guidance
‚ùå "Major problems" ‚Üí Return to appropriate phase
```

#### Phase 2 Collaborative Checks

```markdown
ü§ñ LLM AUTO-CHECK + ü§ù HUMAN VALIDATION:

LLM Automated Assessment:
‚ñ° Can player clear by ignoring one mechanic entirely?
‚ñ° Game reduces to simple parameter optimization (hold time, etc.)?
‚ñ° Only one strategy exists for success?

Human Final Experience Review:
"Based on the walkthrough, do you see:

- Multiple ways to approach the challenge?
- Opportunities for players to improve through understanding?
- Clear 'Aha!' moments or surprising behaviors?

Any red flags about gameplay depth?"
```

#### Phase 3 Human Final Review

```markdown
ü§ù HUMAN FINAL VALIDATION:
"Please review this complete design for any obvious problems:
[Provide concise summary]

Focus on:

- Does this sound implementable and fun?
- Any references to existing games in core mechanics?
- Innovation seems genuine rather than surface-level?
- Overall coherence and implementation readiness?

Final approval to proceed with implementation?"

HUMAN RESPONSE OPTIONS:  
‚úÖ "Approved for implementation" ‚Üí Create specification
üîÑ "Minor issues" ‚Üí Address specific concerns
‚ùå "Major problems" ‚Üí Return to appropriate phase with guidance
```

### 3.2 Final Walkthrough Validation (AUTOMATED + HUMAN CONFIRMATION)

**LLM Automated Final Check + Human Confirmation:**

```markdown
ü§ñ LLM AUTOMATED VALIDATION:
‚ñ° Problem ‚Üí Solution ‚Üí Goal logic chain is unbroken
‚ñ° No automatically detectable warning signs present
‚ñ° 3-second rule maintained after all innovations
‚ñ° Conceptual walkthrough completes without impossible actions

ü§ù HUMAN CONFIRMATION REQUEST:
"Final walkthrough validation:

- Problem ‚Üí Solution ‚Üí Goal logic: [summary]
- User feedback results: [summary]
- Key innovations: [summary]
- Control system: [summary]

Does this complete design feel coherent and implementable?"

HUMAN FINAL APPROVAL:
‚úÖ "Ready for implementation" ‚Üí Proceed to specification
üîÑ "Needs minor adjustments" ‚Üí Address specific issues
‚ùå "Fundamental issues" ‚Üí Return to appropriate phase

If any element fails, return to appropriate phase for fixes.
```

### 3.3 Implementation Specification Template

**Create implementation-ready specification:**

```markdown
# Game Title: [Name]

## Problem-Solution Foundation

- Player Problem: [Specific challenge player faces]
- Core Solution: [How one-button mechanic solves this problem]
- Goal Achievement Logic: [Clear path from problem ‚Üí solution ‚Üí goal]

## Core Mechanics

- Button Press: [Immediate action and visual feedback]
- Button Hold: [Parameter modification and visual indication]
- Button Release: [Action execution and world response]
- Control Target: [Elements directly affected by player]
- Effect Range: [Clear boundaries of player influence]

## Game Loop

- Start State: [Player faces the defined problem]
- Player Action: [How they apply the solution]
- World Response: [How environment changes]
- Success Condition: [Problem resolved, goal achieved]
- Failure Condition: [Problem worsened or new problems created]

## Visual Communication

- Problem Indication: [How player recognizes the challenge]
- Solution Availability: [How player knows when/where to act]
- Action Feedback: [Immediate response to button press/hold/release]
- Progress Indicators: [How player tracks goal achievement]
- Failure Warning: [Early indication of potential failure]

## Innovation Elements

- Light Innovation: [Simple twist that enhances the basic mechanic]
- Physical Concept: [Real-world phenomenon inspiring mechanics]
- Engagement Factor: [What makes this more interesting than the obvious solution]

## User Validation Results

- Understanding Test Results: [User comprehension feedback]
- Engagement Assessment: [User interest and curiosity levels]
- Refinements Made: [Changes based on user feedback]
```

This specification provides everything needed for the implementation guide phase.

## Chapter 6: Converting to Implementation Format

### 6.1 Staged Conversion Process

To preserve all critical design information while converting to the implementation guide format, follow this three-stage process:

#### Stage 1: Information Preservation and Analysis

**Step 1.1: Extract Implementation Categories**

```markdown
# Analyze Environment and Movement Patterns

- Environment Type: [Select from: Central fixed point/Defined path/Open space/Scrolling/Lane/Dynamic surface]
- Movement Pattern: [Select from: Static/Auto/Controlled trajectory/Gravity propulsion/Path following/Point-to-point/Physics floating/State dependent]

# Determine Mechanics Integration

- Count total mechanics used in design
- Assess interaction patterns between mechanics
- Evaluate control complexity and predictability
```

**Step 1.2: Preserve Visual Communication Details**

```markdown
# Create Visual Design Preservation Notes

- UI/UX Elements: [Compile all Problem Indication + Solution Availability + Progress Indicators]
- Feedback Systems: [Preserve detailed Action Feedback specifications]
- Warning Systems: [Maintain Failure Warning specifications]
- Input Response Chain: [Document Button Press ‚Üí Hold ‚Üí Release sequence with visual responses]
```

**Step 1.3: Document Validation Context**

```markdown
# User Testing Context for Implementation

- Validated Understanding Elements: [From Understanding Test Results]
- Proven Engagement Factors: [From Engagement Assessment]
- Applied Refinements: [From Refinements Made]
- Design Decision Rationale: [Link specific choices to user feedback]
```

#### Stage 2: Format Transformation

**Step 2.1: Core Mechanics Conversion**

```markdown
## Core Mechanics

- Button action: [Synthesize from Button Press + Button Hold + Button Release actions]
- World response: [Combine Control Target + Effect Range + World Response descriptions]
- Input pattern: [Map to Press/Hold/Release or Press/Hold or Press only]
- Environment type: [From Stage 1.1 analysis]
- Movement pattern: [From Stage 1.1 analysis]
```

**Step 2.2: Game Loop Transformation**

```markdown
## Game Loop

- Objective: [Extract from Success Condition + Goal Achievement Logic]
- Action: [Simplify from Player Action + detailed button mechanics]
- Obstacle: [Derive from Failure Condition + Problem definition]
- Reward: [Extract success elements from Success Condition]
```

**Step 2.3: Failure Conditions Mapping**

```markdown
## Failure Conditions (Clear Game Over)

- Primary failure condition: [Primary element from Failure Condition]
- Visual feedback: [Combine Failure Warning + relevant Action Feedback]
- Avoidable failure: [Assess from Problem-Solution Foundation + control specifications]
```

#### Stage 3: Implementation Integration

**Step 3.1: Innovation Elements Synthesis**

```markdown
## Innovative Elements

[Direct copy from Innovation Elements section, preserving:

- Light Innovation details
- Physical Concept inspirations
- Engagement Factor specifications]
```

**Step 3.2: Mechanics Integration Assessment**

```markdown
## Mechanics Integration

- Number of mechanics used: [Count from Stage 1.1 analysis]
- Mechanics compatibility: [Assess interaction patterns from preserved details]
- Control evaluation: [Evaluate from Button mechanics + Visual Communication preserved data]
```

**Step 3.3: Implementation Priority Planning**

```markdown
## Implementation Priority

- Phase 1: [Core mechanics from Button action + World response + primary Objective]
- Phase 2: [Enhanced feedback from preserved Visual Communication details]
- Phase 3: [Optimization based on User Validation Results context]
```

### 6.2 Information Preservation Strategy

**Critical Elements to Maintain Throughout Conversion:**

1. **Three-Layer Button Mechanics**: Preserve Press/Hold/Release sequence details in implementation notes
2. **Visual Communication System**: Create detailed UI specification document alongside standard format
3. **User Validation Context**: Maintain testing results as implementation decision rationale
4. **Problem-Solution Logic**: Embed core reasoning into Objective and Action descriptions

**Conversion Quality Check:**

- ‚úÖ All Visual Communication elements have implementation equivalents
- ‚úÖ Button Press/Hold/Release details are preserved in expanded specifications
- ‚úÖ User validation insights inform implementation priority decisions
- ‚úÖ Innovation elements maintain light innovation and physical concept details
- ‚úÖ Problem-Solution Foundation logic is traceable in final format

This staged approach ensures no critical design information is lost while producing the standardized format required for implementation.

---

## üéØ Collaborative Workflow Summary

**Optimized Human-LLM Partnership for One-Button Game Design**

### Time and Effort Optimization

- **Total Session Time**: 35-50 minutes (optimized 4-phase workflow)
- **Human Involvement**: ~30% of total time (strategic validation points)
- **LLM Autonomous Work**: ~70% of total time (systematic processing)

### Key Success Factors

1. **Concrete Theme Selection**: Human validates theme appeal and concreteness from the start
2. **Simple Creative Problem-Solving**: Light innovation applied while maintaining 3-second rule clarity
3. **Early Innovation Validation**: Human confirms creative logic makes sense and feels engaging
4. **Experience Validation**: Human confirms player understanding before final specification  
5. **Implementation Readiness**: Human ensures coherent, implementable design

### Expected Outcomes

- **Higher Success Rate**: Early validation prevents late-stage redesigns
- **Clearer Designs**: Human intuition catches ambiguity LLM might miss
- **Better Innovation**: Human judgment prevents innovation for its own sake
- **Implementable Results**: Human validation ensures practical feasibility

This collaborative approach leverages both LLM systematic processing and human intuitive judgment for optimal game design outcomes.
